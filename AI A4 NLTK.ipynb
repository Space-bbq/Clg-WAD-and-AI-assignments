{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a83cd2bd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Gauri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Gauri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Gauri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter String:The Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and statistical natural language processing for English written in the Python programming language. It supports classification, tokenization, stemming, tagging, parsing, and semantic reasoning functionalities.\n",
      "tokenized words:\n",
      "['The', 'Natural', 'Language', 'Toolkit', ',', 'or', 'more', 'commonly', 'NLTK', ',', 'is', 'a', 'suite', 'of', 'libraries', 'and', 'programs', 'for', 'symbolic', 'and', 'statistical', 'natural', 'language', 'processing', 'for', 'English', 'written', 'in', 'the', 'Python', 'programming', 'language', '.', 'It', 'supports', 'classification', ',', 'tokenization', ',', 'stemming', ',', 'tagging', ',', 'parsing', ',', 'and', 'semantic', 'reasoning', 'functionalities', '.']\n",
      "Word Frequency:\n",
      "the: 2\n",
      "natural: 2\n",
      "language: 3\n",
      "toolkit: 1\n",
      ",: 7\n",
      "or: 1\n",
      "more: 1\n",
      "commonly: 1\n",
      "nltk: 1\n",
      "is: 1\n",
      "a: 1\n",
      "suite: 1\n",
      "of: 1\n",
      "libraries: 1\n",
      "and: 3\n",
      "programs: 1\n",
      "for: 2\n",
      "symbolic: 1\n",
      "statistical: 1\n",
      "processing: 1\n",
      "english: 1\n",
      "written: 1\n",
      "in: 1\n",
      "python: 1\n",
      "programming: 1\n",
      ".: 2\n",
      "it: 1\n",
      "supports: 1\n",
      "classification: 1\n",
      "tokenization: 1\n",
      "stemming: 1\n",
      "tagging: 1\n",
      "parsing: 1\n",
      "semantic: 1\n",
      "reasoning: 1\n",
      "functionalities: 1\n",
      "Filtered Words:\n",
      "['natural', 'language', 'toolkit', ',', 'commonly', 'nltk', ',', 'suite', 'libraries', 'programs', 'symbolic', 'statistical', 'natural', 'language', 'processing', 'english', 'written', 'python', 'programming', 'language', '.', 'supports', 'classification', ',', 'tokenization', ',', 'stemming', ',', 'tagging', ',', 'parsing', ',', 'semantic', 'reasoning', 'functionalities', '.']\n",
      "[('the', 'DT'), ('natural', 'JJ'), ('language', 'NN'), ('toolkit', 'NN'), (',', ','), ('or', 'CC'), ('more', 'JJR'), ('commonly', 'RB'), ('nltk', 'RB'), (',', ','), ('is', 'VBZ'), ('a', 'DT'), ('suite', 'NN'), ('of', 'IN'), ('libraries', 'NNS'), ('and', 'CC'), ('programs', 'NNS'), ('for', 'IN'), ('symbolic', 'JJ'), ('and', 'CC'), ('statistical', 'JJ'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('for', 'IN'), ('english', 'JJ'), ('written', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('python', 'NN'), ('programming', 'NN'), ('language', 'NN'), ('.', '.'), ('it', 'PRP'), ('supports', 'VBZ'), ('classification', 'NN'), (',', ','), ('tokenization', 'NN'), (',', ','), ('stemming', 'VBG'), (',', ','), ('tagging', 'VBG'), (',', ','), ('parsing', 'NN'), (',', ','), ('and', 'CC'), ('semantic', 'JJ'), ('reasoning', 'NN'), ('functionalities', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Name: Gauri Khanzode \n",
    "# Roll no.: 3336\n",
    "# Assignment No.4\n",
    "# Problem Statement\n",
    "# write a program for the Information Retrieval System using appropriate NLP T\n",
    "# a. Text tokenization\n",
    "# b. Count Word frequency\n",
    "# c. Remove stop words\n",
    "# d. POS tagging\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tag import pos_tag\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "#Define the text to be analysed\n",
    "text=input(\"Enter String:\")\n",
    "\n",
    "#Tokenize the text into words\n",
    "words=word_tokenize(text)\n",
    "print(\"tokenized words:\")\n",
    "print(words)\n",
    "\n",
    "#Convert all words to lowercase\n",
    "words = [word.lower() for word in words]\n",
    "\n",
    "#Count the frequency of each word\n",
    "fdist = FreqDist(words)\n",
    "print(\"Word Frequency:\")\n",
    "for word, freq in fdist.items():\n",
    "    print(f\"{word}: {freq}\")\n",
    "\n",
    "#Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = [word for word in words if word.casefold() not in stop_words]\n",
    "print(\"Filtered Words:\")\n",
    "print(filtered_words)\n",
    "\n",
    "#Perform POS tagging\n",
    "pos_tags = pos_tag(words)\n",
    "print(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7d39e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
